{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chainer_repro",
      "provenance": [],
      "authorship_tag": "ABX9TyNRd/RPPZdqNrvi/3J8ZzCg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tjsgertsen/Chainer_repro/blob/master/Chainer_repro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFhtiSsKxuzw",
        "colab_type": "text"
      },
      "source": [
        "# Reproduction by using Chainer\n",
        "\n",
        "To reproduce the results of the paper 'Between-class Learning for Image Classification' the code is made available by the authors. However, this code is written in python 2 with a very early version of the Chainer library. Since we had to work on Google Colabs in order to make use of GPU computing this old versions did not work anymore. Therefore, we decided to approach the reproduction in two ways: \n",
        "1. by building our own version in Pytorch (other google colab)\n",
        "2. Update the original code from the authors by making it compatible with python 3 and the newest version of Chainer. To keep the structure of the code intact it was modified offline whereafter is loaded into this Google Colab. Furthermore, an effort is made to change as little as possible since the goal is to reproduce. The (offline) code can be found in the following Github repository: [https://github.com/tjsgertsen/Chainer_repro.git](https://)\n",
        "\n",
        "First, your google drive is mounted. Change `root_path` to your folder where the (offline) code is stored in google drive. You still have to download the CIFAR-10 dataset into a folder named \"datasets\" within the same folder as the code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAwd3328p7bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import chainer\n",
        "\n",
        "# mount drive\n",
        "drive.mount('/content/gdrive', force_remount=True) \n",
        "\n",
        "# change working directory\n",
        "root_path='/content/gdrive/My Drive/Cloud Sync/bc_learning_image-master_python3' \n",
        "os.chdir(root_path)\n",
        "check = os.getcwd()\n",
        "print(f'Check: the current working directory is {check}')\n",
        "\n",
        "!python --version\n",
        "print(f'Chainer {chainer.__version__}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vi6T4jo5SEK",
        "colab_type": "text"
      },
      "source": [
        "# Run Script\n",
        "\n",
        "In order to initialize the code the following python command is triggered. A few examples for variatonal settings are commented. Please construct your own problem that you want to reproduce and insert the right path to your google drive folder with the files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI0UjBNZuLKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Check chainer version: {chainer.__version__}')\n",
        "%matplotlib inline\n",
        "\n",
        "# command to run with cifar-10 dataset and standard method\n",
        "# !python main.py --dataset cifar10 --netType convnet --nTrials 3 --data /content/gdrive/My\\ Drive/Cloud\\ Sync/bc_learning_image-master_python3/datasets/cifar-10-batches-py\n",
        "\n",
        "# command to run with cifar-10 dataset and BC(+) method\n",
        "!python main.py --dataset cifar10 --netType convnet --nTrials 2 --data /content/gdrive/My\\ Drive/Cloud\\ Sync/bc_learning_image-master_python3/datasets/cifar-10-batches-py --BC --plus \\\n",
        "--save /content/gdrive/My\\ Drive/Cloud\\ Sync/bc_learning_image-master_python3/results\n",
        "\n",
        "# command to run with cifar-100 dataset\n",
        "#!python main.py --dataset cifar100 --netType convnet --data /content/gdrive/My Drive/Cloud Sync/bc_learning_image-master_python3/datasets/cifar-100-python --BC --plus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxxgvf2G6USB",
        "colab_type": "text"
      },
      "source": [
        "# Results\n",
        "\n",
        "Since the runtime is restricted by Google Colabs we tried to reproduce table 2 of the paper for all learning methods with the CIFAR-10 dataset and an 11-layer CNN. The standard deviation is constructed by 5 trials and 250 epoch per trial, of each learning method. The results that are found are as following:\n",
        "\n",
        "Learning method | Paper results | Reproduction\n",
        "--- | --- | ---\n",
        "Standard | $6.07 \\pm 0.04$ | $6.11 \\pm 0.15$\n",
        "BC | $5.40 \\pm 0.07$ | $5.39 \\pm 0.07$\n",
        "BC+ | $5.22 \\pm 0.04$ | $5.26 \\pm 0.16$"
      ]
    }
  ]
}